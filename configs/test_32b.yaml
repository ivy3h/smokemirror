# Smokemirror Test Configuration
# For Qwen3-32B model with thinking mode enabled

# Model Configuration
model:
  name: "Qwen/Qwen3-32B"
  device: "auto"
  load_in_4bit: false  # Full precision with multi-GPU
  load_in_8bit: false
  torch_dtype: "bfloat16"
  max_new_tokens: 4096
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  do_sample: true
  repetition_penalty: 1.1

# Generation Settings
generation:
  min_plot_points: 20
  max_plot_points: 30
  min_conspirators: 3
  max_conspirators: 4
  min_suspects: 4
  max_suspects: 6
  discovery_paths_threshold: 1
  initial_discovery_paths: 8

# Suspense Controller Settings
suspense:
  initial_level: 3
  max_level: 10
  path_close_probability: 0.6
  new_path_probability: 0.2
  collision_check_sensitivity: 0.5

# Reader Simulation Settings
reader_simulation:
  enabled: true
  num_readers: 3  # Informational - actual count computed from reader_roles
  reader_model: "Qwen/Qwen2.5-7B-Instruct"  # Separate smaller model for reader evaluation
  reader_roles:
    - name: "logic_analyst"
      focus: "logical consistency and deduction quality"
      weight: 1.5
      count: 1  # Number of instances (e.g., set to 3 for 3 logic analysts)
    - name: "intuitive_reader"
      focus: "character behavior and emotional engagement"
      weight: 1.0
      count: 1  # Number of instances
    - name: "genre_expert"
      focus: "mystery pacing and narrative structure"
      weight: 1.2
      count: 1  # Number of instances
  checkpoints: [5, 10, 15, 20, 25]
  suspense_threshold: 6.0

# Refinement Settings
refinement:
  max_iterations: 0
  consensus_threshold: 2
  critical_issue_weight: 3.0
  moderate_issue_weight: 1.5
  minor_issue_weight: 0.5

# Output Settings
output:
  save_intermediate: true
  output_dir: "outputs"
  format: "markdown"

# Reproducibility
seed: 42

# Logging
logging:
  level: "INFO"
  save_logs: true
